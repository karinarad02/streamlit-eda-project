import streamlit as st
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.feature_selection import SelectKBest, f_classif, f_regression

from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.svm import SVC, SVR

from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score,
    mean_absolute_error, mean_squared_error, r2_score, roc_curve
)

sns.set_theme(style="whitegrid")
plt.rcParams['figure.figsize'] = (5, 3)

def run():
    st.title("ðŸ¤– Modul Machine Learning")

    # =========================
    # Verificare date
    # =========================
    if "data" not in st.session_state:
        st.warning("Mai Ã®ntÃ¢i Ã®ncarcÄƒ È™i curÄƒÈ›Äƒ datele Ã®n modulul EDA.")
        st.stop()

    df = st.session_state["data"].copy()

    # =========================
    # Feature engineering: grupe de vÃ¢rstÄƒ
    # =========================
    if "Varsta" in df.columns:
        df["Grupa_varsta"] = pd.cut(
            df["Varsta"],
            bins=[0, 25, 35, 45, 60, 100],
            labels=["<25", "25-35", "35-45", "45-60", "60+"]
        )

    st.subheader("Dataset folosit")
    st.dataframe(df.head())

    # ======================================================
    # 1. PROBLEM SETUP
    # ======================================================
    st.header("1. Problem Setup")

    # Target recomandat automat
    target = st.selectbox(
        "SelecteazÄƒ coloana È›intÄƒ (target)",
        options=[col for col in df.columns if col in ["Grupa_varsta", "Oras"]] 
        or list(df.columns)
    )

    # Features: eliminÄƒm ID/Nume
    default_features = [c for c in df.columns if c not in [target, "ID", "Nume"]]
    features = st.multiselect(
        "SelecteazÄƒ feature-uri",
        default_features,
        default=default_features
    )

    X = df[features]
    y = df[target]

    problem_type = "classification" if y.dtype == "object" or y.nunique() <= 10 else "regression"
    st.info(f"Tip problemÄƒ detectat automat: **{problem_type.upper()}**")

    # ======================================================
    # 2. PREPROCESARE
    # ======================================================
    st.header("2. Preprocesare")

    numeric_features = X.select_dtypes(include=np.number).columns
    categorical_features = X.select_dtypes(exclude=np.number).columns

    impute_strategy = st.selectbox("Imputare numericÄƒ", ["mean", "median", "most_frequent"])
    scaler_option = st.selectbox("Scalare numericÄƒ", ["None", "StandardScaler", "MinMaxScaler"])
    use_feature_selection = st.checkbox("AplicÄƒ SelectKBest")
    k_features = st.slider(
        "NumÄƒr features pÄƒstrate",
        1, max(1, X.shape[1]), min(10, X.shape[1])
    ) if use_feature_selection else None

    # Pipeline numeric
    num_steps = [("imputer", SimpleImputer(strategy=impute_strategy))]
    if scaler_option == "StandardScaler":
        num_steps.append(("scaler", StandardScaler()))
    elif scaler_option == "MinMaxScaler":
        num_steps.append(("scaler", MinMaxScaler()))
    num_pipeline = Pipeline(num_steps)

    # Pipeline categoric
    cat_pipeline = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("encoder", OneHotEncoder(handle_unknown="ignore"))
    ])

    preprocessor = ColumnTransformer([
        ("num", num_pipeline, numeric_features),
        ("cat", cat_pipeline, categorical_features)
    ])

    # ======================================================
    # 3. TRAIN / TEST SPLIT
    # ======================================================
    st.header("3. Train / Test Split")
    test_size = st.slider("Test size", 0.1, 0.5, 0.2)
    random_state = st.number_input("Random state", 0, 9999, 42)

    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=test_size,
        random_state=random_state,
        stratify=y if problem_type == "classification" else None
    )

    # ======================================================
    # 4. MODELE
    # ======================================================
    st.header("4. Modele")
    models = {}

    if problem_type == "classification":
        if st.checkbox("Logistic Regression"):
            C = st.slider("LR: C", 0.01, 10.0, 1.0)
            models["Logistic Regression"] = LogisticRegression(C=C, max_iter=1000)

        if st.checkbox("Random Forest Classifier"):
            n_estimators = st.slider("RF: n_estimators", 50, 300, 100)
            max_depth = st.slider("RF: max_depth", 2, 20, 10)
            models["Random Forest"] = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                min_samples_leaf=5,
                class_weight="balanced",
                random_state=random_state
            )

        if st.checkbox("SVM (SVC)"):
            C = st.slider("SVC: C", 0.1, 10.0, 1.0)
            kernel = st.selectbox("SVC kernel", ["rbf", "linear"])
            models["SVM"] = SVC(C=C, kernel=kernel, probability=True)

    else:
        if st.checkbox("Linear Regression"):
            models["Linear Regression"] = LinearRegression()

        if st.checkbox("Random Forest Regressor"):
            n_estimators = st.slider("RF: n_estimators", 50, 300, 100)
            max_depth = st.slider("RF: max_depth", 2, 20, 10)
            models["Random Forest"] = RandomForestRegressor(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=random_state
            )

        if st.checkbox("SVR"):
            C = st.slider("SVR: C", 0.1, 10.0, 1.0)
            models["SVR"] = SVR(C=C)

    # ======================================================
    # 5. ANTRENARE & EVALUARE
    # ======================================================
    st.header("5. Evaluare & Comparare")
    metric_select = st.selectbox(
        "MetricÄƒ pentru best model",
        ["Accuracy", "F1"] if problem_type == "classification" else ["RMSE", "R2"]
    )

    if st.button("ðŸš€ Train models") and models:
        results = []

        for name, model in models.items():
            steps = [("preprocessor", preprocessor)]
            if use_feature_selection:
                selector = SelectKBest(
                    score_func=f_classif if problem_type == "classification" else f_regression,
                    k=k_features
                )
                steps.append(("selector", selector))
            steps.append(("model", model))
            pipeline = Pipeline(steps)

            pipeline.fit(X_train, y_train)
            preds = pipeline.predict(X_test)

            st.subheader(name)

            # =========================
            # CLASIFICARE
            # =========================
            if problem_type == "classification":
                acc = accuracy_score(y_test, preds)
                prec = precision_score(y_test, preds, average="weighted")
                rec = recall_score(y_test, preds, average="weighted")
                f1 = f1_score(y_test, preds, average="weighted")

                st.metric("AcurateÈ›e", f"{acc:.3f}")
                st.text("Classification report:")
                st.text(classification_report(y_test, preds))

                results.append({"Model": name, "Accuracy": acc, "Precision": prec, "Recall": rec, "F1": f1})

                # Matrice de confuzie
                cm = confusion_matrix(y_test, preds)
                labels = np.unique(y_test)
                fig, ax = plt.subplots()
                sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=labels, yticklabels=labels, ax=ax)
                ax.set_xlabel("PredicÈ›ii")
                ax.set_ylabel("Valori reale")
                ax.set_title("Matrice de confuzie")
                st.pyplot(fig)

                # ROC AUC (doar binar)
                if hasattr(model, "predict_proba") and y.nunique() == 2:
                    y_proba = pipeline.predict_proba(X_test)[:, 1]
                    roc_auc = roc_auc_score(y_test, y_proba)
                    st.write(f"**ROC AUC = {roc_auc:.3f}**")
                    fpr, tpr, _ = roc_curve(y_test, y_proba)
                    fig, ax = plt.subplots()
                    ax.plot(fpr, tpr, label=f"ROC Curve (AUC={roc_auc:.3f})")
                    ax.plot([0, 1], [0, 1], linestyle="--", label="No Skill")
                    ax.set_xlabel("False Positive Rate")
                    ax.set_ylabel("True Positive Rate")
                    ax.set_title("ROC Curve")
                    ax.legend()
                    st.pyplot(fig)

            # =========================
            # REGRESIE
            # =========================
            else:
                mae = mean_absolute_error(y_test, preds)
                rmse = np.sqrt(mean_squared_error(y_test, preds))
                r2 = r2_score(y_test, preds)

                results.append({"Model": name, "MAE": mae, "RMSE": rmse, "R2": r2})

                fig, ax = plt.subplots()
                ax.scatter(y_test, preds)
                ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], linestyle="--")
                ax.set_xlabel("Valori reale")
                ax.set_ylabel("PredicÈ›ii")
                ax.set_title("Actual vs Predicted")
                st.pyplot(fig)

        # Comparare modele
        results_df = pd.DataFrame(results)
        st.subheader("Comparare modele")
        st.dataframe(results_df)

        best_model = (
            results_df.sort_values(metric_select, ascending=False).iloc[0]
            if metric_select != "RMSE"
            else results_df.sort_values(metric_select).iloc[0]
        )
        st.success(f"ðŸ† Best model: **{best_model['Model']}**")
